#!/usr/bin/env python3
# -*- coding: UTF-8 -*-
"""
Description:
py3bt_tracker.py is a cross-platform standalone ephemeral tracker for torrents written in Python3.
The development emphasis is on zero-configuration "just works" software.
Currently implemented using a multidimentional array in memory and the Tornado Web Server.

google_define('ephemeral') #returns: adjective - lasting for a very short time -synonyms: transient, short-lived, brief

Usage guide:
1) double click on the .exe for your os
2) point your torrents to http://127.0.0.1:9000/announce 
where 127.0.0.1 is substituted for your IP obtained from ipconfig (for lans)
Note: If the firewall annoyance pops up, add as an exception.

Important Release Notes:
-Runs on port 9000, with a requested check-in interval of 4 minutes by default (change via command line)

3) (if crazy enough to use this on the internets) public ip can be obtained from icanhazip.com, and remember to port forward
^-not intended use case but should still work maybe-^

Current version: 1.0.0-rc1

###stop reading now###

feature/bug Todo list:
-incomplete and complete should increment/decrement -partially done, need to improve "update" code still
-text/plain bencoded response -done
-error codes should be -done
1) text/plain -done
2) human readable -done
3) sent back as becoded responses -done
-figure out how to use github -partially done
-add ipv6 support at some point -will get around to it eventually...
-Should return a response of peers picked randomly from peer pool for a torrent, will get around to it eventually...
-figure out how to read, store and respond with dns names...somehow. -No idea how to implement that, maybe just resolve first and store ip's? or does spec require sending back dns names...x.x
-change db key from peer_id to ip/port combination to limit potential for abuse in untrustworthy enviornments
-udp tracker support - beep 15 -Does Tornado even know what UDP is? maybeh
-will also add obfuscation feature if I ever get that bored
-improve performance for use in WANs (production quality code optimizations + fully async web server)
-maybe implement logging, maybe
"""

import hashlib
import urllib.parse
import binascii
import time

import os
#import random

import tornado.ioloop
import tornado.web
import tornado.httpserver
import tornado.httputil
#from tornado.concurrent import Future
from tornado.options import define, options, parse_command_line

define("port", default=9000, help="run on the given port", type=int)
define("debug", default=False, help="run in debug mode")

#configurable settings
tracker_port=9000
request_interval=40
#wipe_database every this many seconds, 3600 seconds = 1 hr
#database_lifespan=3600
database_lifespan=360
max_peers_in_response=30

#internal variables
#clients will receive an error if they request more than this (in seconds)
minimum_interval=int(request_interval/4)
consider_peers_dead_after=int(request_interval*1.8)
#clean_database_every=int(request_interval*200)
clean_database_every=int(request_interval*1.4)
#initalize random number gen
#random.seed()

#error [response] codes
#client query must be an http get request
invalid_http_get_request=100
missing_info_hash=101
missing_peer_id=102
missing_port=103
#must be 20 bytes long
invalid_info_hash=150
#must be 20 bytes long
invalid_peer_id=151
#tracker has a maximum peer response list and client requested more than that (30-50), send back a warning
invalid_num_want=152
#reserved for private trackers that don't auto-add new info_hashes
info_hash_not_found=200
#clients have a minimum interval between requests, return this error if a client asked again before allowed to
request_too_soon=500
unspecified_error=900


def bencode(encodeString,bentype):
    if bentype == 'string':
        return str(len(encodeString))+":"+encodeString
    if bentype == 'int':
        return "i"+str(encodeString)+"e"
    if bentype == 'list':
        return "l"+str(encodeString)+"e"
    if bentype == 'dictionary':
        return "d"+str(encodeString)+"e"
    return

#bencode the static strings
#could also store these as global variables since they will never need to be rencoded, but w/e
bencoded_failure_string=bencode('failure reason','string')
bencoded_warning_string=bencode('warning message','string')
bencoded_interval_string=bencode('interval','string')
bencoded_min_interval_string=bencode('min interval','string')
bencoded_tracker_id_string=bencode('tracker id','string')
bencoded_complete_string=bencode('complete','string')
bencoded_incomplete_string=bencode('incomplete','string')
bencoded_peers_string=bencode('peers','string')
bencoded_peer_id_string=bencode('peer id','string')
bencoded_ip_string=bencode('ip','string')
bencoded_port_string=bencode('port','string')
bencoded_peers_string=bencode('peers','string')    
bencoded_failure_reason_string=bencode('failure reason','string')
bencoded_failure_code_string=bencode('failure code','string')


#returns a human redable bencoded response
#could implement retry feature here (beep 31), but like why...
def errorHandler(error_code):
    error_code=int(error_code)
    #needs to return
    #d14:failure reason32:invalid info hash and/or peer ide
    #so dictionary with a string object inside of it
    bencoded_specific_error_string='invalid'
    if error_code == 100:
        bencoded_specific_error_string=bencode('invalid_http_get_request','string')
    if error_code == 101:
        bencoded_specific_error_string=bencode('missing_info_hash','string')
    if error_code == 102:
        bencoded_specific_error_string=bencode('missing_peer_id','string')
    if error_code == 103:
        bencoded_specific_error_string=bencode('missing_port','string')
    if error_code == 150:
        bencoded_specific_error_string=bencode('invalid_info_hash','string')
    if error_code == 151:
        bencoded_specific_error_string=bencode('invalid_peer_id','string')
    if error_code == 152:
        bencoded_specific_error_string=bencode('invalid_num_want','string')
    if error_code == 200:
        bencoded_specific_error_string=bencode('info_hash_not_found','string')
    if error_code == 500:
        bencoded_specific_error_string=bencode('silly client is silly','string')
    if error_code == 900:
        bencoded_specific_error_string=bencode('unspecified_error','string')
    response=bencoded_failure_reason_string+bencoded_specific_error_string+bencoded_failure_code_string+bencode(error_code,'int')
    return bencode(response,'dictionary')


#info_hash and peer_id are URL encoded, so need to decode them
#1) if prefix present, seperate, and then decode rest of string into bytes
#2) if prefix not present, then just convert to bytes
#3) stored form is no longer url encoded and in hex ready to get printed to the console
#4) be sure to go from hex->binary again right before transmission
def decodeURL(url_string):
    raw_encoded_url_string=url_string
    #a length of 24 hex digits means 12 bytes, 12 bytes of hex + prefix = 20 bytes if prefix is 8 bytes long
    #35-3 (from hex to string conversion) is 32-8 =24, 24/2 = 12+8 = 20 bytes
    #Note: for peer_ids, the client version could be encoded into the binary form itself instead of shown raw (prefixed) in the url (Aria does this)
    #print("raw_encoded_url_string: "+str(raw_encoded_url_string))
    if raw_encoded_url_string.rfind('-') == -1:
        decoded_url_string=urllib.parse.unquote_to_bytes(raw_encoded_url_string)
        #print(str(decoded_url_string))
        if len(decoded_url_string) != 20:
            print(url_string)
            return 'error'
        temp=str(binascii.b2a_hex(decoded_url_string))
        #temp=str(decoded_url_string)
        #print(temp)
        decoded_url_string=temp[2:len(temp)-1]
    elif raw_encoded_url_string.rfind('-') != -1:
        prefix=raw_encoded_url_string[:raw_encoded_url_string.rfind('-')+1]
        #print(str(len(prefix))+prefix)
        peer_id_part=raw_encoded_url_string[raw_encoded_url_string.rfind('-')+1:]
        decoded_url_string=urllib.parse.unquote_to_bytes(peer_id_part)
        #print(str(decoded_url_string))
        if len(prefix)+len(decoded_url_string) != 20:
            print(url_string)
            return 'error'
        temp=str(binascii.b2a_hex(decoded_url_string))
        #temp=str(decoded_url_string)
        temp=temp[2:len(temp)-1]
        #print(temp)
        decoded_url_string=prefix+temp
    #print("decoded_url_string: "+decoded_url_string)
    return decoded_url_string


#returns a requestObject containing all arguments or a BT error for invalid data
def parseRawRequest(rawquery):
    #raw query
    query=rawquery
    #print("query: " + query)

    #print the number of items in uri
    queryItems=len(query.split("&"))
    #print("queryItems: " + str(queryItems))

    #place each item into a dictionary container
    client_rawRequestContainer=dict({})
    for i in range(queryItems):
        
        #this split will not work with invalid data, will http error 500 the server (internal server error)
        #print (str(i)+": "+(query.split("&")[i]))
        temp=query.split("&")[i]
        client_rawRequestContainer.update([temp.split("=")])

    #initalize temp variables
    client_info_hash="invalid"
    client_peer_id="invalid"
    client_port="invalid"
    client_uploaded="invalid"
    client_downloaded="invalid"
    client_left="invalid"
    client_compact="invalid"
    client_no_peer_id="invalid"
    client_event="invalid"
    client_ip="invalid"
    client_numwant="invalid"
    client_key="invalid"
    client_trackerid="invalid"
    client_corrupt="invalid"

    requestObject=({})

    if ('info_hash' in client_rawRequestContainer) == (True):
        client_info_hash=decodeURL(client_rawRequestContainer["info_hash"])
        if client_info_hash == 'error':
            print("error: info_hash is invalid")
            requestObject['error']=invalid_info_hash
            return requestObject
    else:
        print("error: info_hash not present")
        requestObject['error']=missing_info_hash
        return requestObject

    if ('peer_id' in client_rawRequestContainer) == (True):
        client_peer_id=decodeURL(client_rawRequestContainer["peer_id"])
        if client_peer_id == 'error':
            print("error: peer_id is invalid")
            requestObject['error']=invalid_peer_id
            return requestObject
    else:
        print("error: peer_id not present")
        requestObject['error']=missing_peer_id
        return requestObject

    if ('port' in client_rawRequestContainer) == (True):
        client_port=client_rawRequestContainer["port"]
    else:
        print("error: port not present")
        requestObject['error']=missing_port
        return requestObject

    if ('uploaded' in client_rawRequestContainer) == (True):
        client_uploaded=client_rawRequestContainer["uploaded"]
    else:
        pass
        #print("error: uploaded not present")

    if ('downloaded' in client_rawRequestContainer) == (True):
        client_downloaded=client_rawRequestContainer["downloaded"]
    else:
        pass
        #print("error: downloaded not present")

    if ('left' in client_rawRequestContainer) == (True):
        client_left=client_rawRequestContainer["left"]
    else:
        pass
        #print("error: left not present")

    if ('compact' in client_rawRequestContainer) == (True):
        client_compact=client_rawRequestContainer["compact"]
    else:
        pass
        #print("error: compact not present")

    if ('no_peer_id' in client_rawRequestContainer) == (True):
        client_no_peer_id=client_rawRequestContainer["no_peer_id"]
    else:
        pass
        #print("error: no_peer_id not present")

    if ('event' in client_rawRequestContainer) == (True):
        client_event=client_rawRequestContainer["event"]
    else:
        pass
        #print("error: event not present")

    if ('ip' in client_rawRequestContainer) == (True):
        client_ip=client_rawRequestContainer["ip"]
    else:
        pass
        #print("error: ip not present")
 
    if ('numwant' in client_rawRequestContainer) == (True):
        client_numwant=client_rawRequestContainer["numwant"]
    else:
        pass
        #print("error: numwant not present")

    if ('key' in client_rawRequestContainer) == (True):
        #client_key=decodeURL(client_rawRequestContainer["key"])
        client_key=client_rawRequestContainer["key"]
    else:
        pass
        #print("error: key not present")

    if ('trackerid' in client_rawRequestContainer) == (True):
        client_trackerid=client_rawRequestContainer["trackerid"]
    else:
        pass
        #print("error: trackerid not present")

    if ('corrupt' in client_rawRequestContainer) == (True):
        client_corrupt=client_rawRequestContainer["corrupt"]
    else:
        pass
        #print("error: corrupt not present")

    #print_client_info (debugging code)
    #print("client_info_hash: "+client_info_hash)
    #print("client_peer_id: "+client_peer_id)
    #print("client_port: "+client_port)
    #print("client_uploaded: "+client_uploaded)
    #print("client_downloaded: "+client_downloaded)
    #print("client_left: "+client_left)
    #print("client_compact: "+client_compact)
    #print("client_no_peer_id: "+client_no_peer_id)
    #print("client_event: "+client_event)
    #print("client_ip: "+client_ip)
    #print("client_numwant: "+client_numwant)
    #print("client_key: "+client_key)
    #print("client_trackerid: "+client_trackerid)
    #print("client_corrupt: "+client_corrupt)

    #so now need to return an object the values as keys
    #rebuild the dictionary!
    if client_info_hash != "invalid":
        requestObject["client_info_hash"]=client_info_hash
    if client_peer_id != "invalid":
        requestObject["client_peer_id"]=client_peer_id
    if client_port != "invalid":
        requestObject["client_port"]=client_port
    if client_uploaded != "invalid":
        requestObject["client_uploaded"]=client_uploaded
    if client_downloaded != "invalid":
        requestObject["client_downloaded"]=client_downloaded
    if client_left != "invalid":
        requestObject["client_left"]=client_left
    if client_compact != "invalid":
        requestObject["client_compact"]=client_compact
    if client_no_peer_id != "invalid":
        requestObject["client_no_peer_id"]=client_no_peer_id
    if client_event != "invalid":
        requestObject["client_event"]=client_event
    if client_ip != "invalid":
        requestObject["client_ip"]=client_ip
    if client_numwant != "invalid":
        requestObject["client_numwant"]=client_numwant
    if client_key != "invalid":
        requestObject["client_key"]=client_key
    if client_trackerid != "invalid":
        requestObject["client_trackerid"]=client_trackerid
    if client_corrupt != "invalid":
        requestObject["client_corrupt"]=client_corrupt
    return requestObject


class Database:
    def __init__(self):
        #create table containing global list of all known torrents
        #masterlist is a dictionary mapping md5 hashes of info_hash to table_objects (dictionary)
        #table objects are dictionaries that each contain 3 entries: complete (int), incomplete (int) and another dictionary
        #each dictionary of client data can be contains an md5 key which references a list containing: (peer_id, is_seed,ipv4_dottedstring,client_port,ip_in_hex,port_in_hex)
        global master_info_hash_table
        master_info_hash_table=dict({})
        #the idea is to wipe the database every hour or so for no particular reason
        global initialization_time
        initialization_time=int(time.time())
        #purge the database of stale peers
        global last_database_cleanup
        last_database_cleanup=int(time.time())

    def get_complete(self,info_hash):
        current_query=hashlib.md5()
        current_query.update(info_hash.encode('utf-8'))
        #return the value of complete of the referenced table
        return master_info_hash_table[current_query.hexdigest()]['complete']

    def get_incomplete(self,info_hash):
        current_query=hashlib.md5()
        current_query.update(info_hash.encode('utf-8'))
        #return the value of complete of the referenced table
        return master_info_hash_table[current_query.hexdigest()]['incomplete']

    #possible scenarios are: non-compact, non-compact no seeds, compact, compact no seeds
    #peer_List = tracker_db.get_peerList(current_client_info_hash,clientWantsNormalOrCompactResponse)
    #values are (hash,normal/compact)
    def get_peerList(self,client_info_hash,compactOrNormal='normal'):
        #itterate through that list to create the compact peer list of IPs/ports (in hex)
        #-each torrent_table (linked to an info_hash) contains peers+associated data (named after peer_id), an integer of incomplete (non seed peers), and completed (seeders)
        #create a new table using the table_id and an individual peer of type list containing (a peer_id,is_seed,address,client_port,address_hex, port_hex)

        current_query=hashlib.md5()
        current_query.update(client_info_hash.encode('utf-8'))
        info_hash_table=master_info_hash_table[current_query.hexdigest()]

        #build a peerlist
        #md5 hashes of the peer_id are used as keys
        info_hashes_table_keys=info_hash_table.keys()
        peer_list=[]
        if compactOrNormal.lower() == 'normal':
            for i in (info_hashes_table_keys):
                if (i != 'complete'):
                    if (i != 'incomplete'):
                        peer_list.append(info_hash_table[i][0])
                        peer_list.append(info_hash_table[i][2])
                        peer_list.append(info_hash_table[i][3])
        elif compactOrNormal.lower() == 'compact':
            for i in (info_hashes_table_keys):
                if (i != 'complete'):
                    if (i != 'incomplete'):
                        peer_list.append(info_hash_table[i][4])
                        peer_list.append(info_hash_table[i][5])
        #print(peer_list)
        return peer_list

    def updateClient(self,client_object,client_remote_ip):
        #Todo: update this very old function to handle updates better, should not just override existing peers and also
        #take into account previously existing seed status, new status and events and factor all of that into updated incomplete/complete numbers
        #for the relevant info_hash

        #use the client dictionary along with IP info to create a Peer
        #determine if a client_ip was used in the client_dictionary, if so use it, else use the IP from the connection instead
        #create table containing global list of all known torrents
        #masterlist is a dictionary mapping md5 hashes of info_hash to table_objects (dictionary)
        #table objects are dictionaries that each contain 3 entries: complete (int), incomplete (int) and another dictionary
        #each dictionary of client data can be contains an md5 key which references a list containing: (raw_peer_id, is_seed,ipv4_dottedstring,client_port,ipv4_hex,port_hex)

        global master_info_hash_table
        client_info_hash=hashlib.md5()
        client_info_hash.update(client_object['client_info_hash'].encode('utf-8'))
        client_peer_id=hashlib.md5()
        client_peer_id.update(client_object['client_peer_id'].encode('utf-8'))

        #could prolly handle this in a smarter way
        if 'client_left' in client_object:
            if (client_object['client_left'] == 0):
                is_seed=True
            elif (client_object['client_left'] != 0):
                is_seed=False
        else:
            is_seed=False

        #very easy to abuse this if peer_id.md5 hashes are used as keys, change db key to limit potential abuse
        if 'client_ip' in client_object:
            client_ip=client_object['client_ip']
        elif 'client_ip' not in client_object:
            client_ip=client_remote_ip

        client_port=client_object['client_port']

        #this returns a dictionary object (completed: int, incomplete: int,peer_id.md5 : client_list)
        #master_info_hash_table[client_info_hash.hexdigest()]
        #this returns the client's list (peer_id, is_seed,ipv4_dottedstring,client_port,ipv4_hex,port_hex)
        #master_info_hash_table[client_info_hash.hexdigest()][client_peer_id.hexdigest()]
        #get the ip using master_info_hash_table[client_info_hash.hexdigest()][client_peer_id.hexdigest()][2]

        #possible scenarios
        #if info_hash doesn't exist in master_table, create info_hash_table entry
        #then just always create a new peer (set the specified peer_id.md5 to that newpeer object)

        #if info_hash doesn't exist in master table, create info_hash table entry
        if client_info_hash.hexdigest() not in master_info_hash_table:
            #set the info_hash.md5 as the key to a new dictionary object
            master_info_hash_table[client_info_hash.hexdigest()]=self.createInfoHashTable()
            #if this new client is a seed, increment completes
            if (is_seed==True):
                #Note: this will "taint" the completed pool, so total "finished" now includes the inital seeder
                master_info_hash_table[client_info_hash.hexdigest()]['complete']=master_info_hash_table[client_info_hash.hexdigest()]['complete']+1
            #if the client is a new client and not a seed, increment the incomplete list
            elif (is_seed!=True):
                master_info_hash_table[client_info_hash.hexdigest()]['incomplete']=master_info_hash_table[client_info_hash.hexdigest()]['incomplete']+1

        #if the client has an event, and if that event is completed, increment seeders and decriment incomplete
        if 'client_event' in client_object:
            if (client_object['client_event'].lower()=='Completed'.lower()):
                master_info_hash_table[client_info_hash.hexdigest()]['complete']=master_info_hash_table[client_info_hash.hexdigest()]['complete']+1
                master_info_hash_table[client_info_hash.hexdigest()]['incomplete']=master_info_hash_table[client_info_hash.hexdigest()]['incomplete']-1

        #this has potential for abuse if a peer floods the tracker with a target ip using the same info hash and different peer_id's
        #will redirect the swarm to try to form connections to the target ip as a potential DDoS to that ip
        #or even to change the information of another peer in the db by finding out their peer id
        #potential fix: might be better to be hash the IP/port combination of the peer instead of the easily spoofable peer_id and use that as the db key instead
        #however, this is not relevant in a LAN enviornment and won't form enough connections per second for a lasting DoS due to the default behavior of end-user
        #clients to back off for extremely long periods after a failed attempt to contact a tracker so leave it, but change this for more optimized use on the internets
        #set the peer_id.md5 as the key to a new list object
        master_info_hash_table[client_info_hash.hexdigest()][client_peer_id.hexdigest()]=self.createPeer(client_object['client_peer_id'],is_seed,client_ip,client_port)
        return


    #table objects are dictionaries that each contain 3 entries: complete (int), incomplete (int) and another dictionary
    def createInfoHashTable(self):
        return {'complete':0,'incomplete':0}


    #each peer list returns containing: (peer_id, is_seed,ip_address,client_port,ip_hex,port_hex,created time)
    #types are (rawbytes, bool, string, int, string, string)
    def createPeer(self,peer_id,is_seed,client_ip_address,client_port):
        #convert IP to hexadecimal format
        #if dealing with an ipv4 address, then count the octets
        #split into 4 sections
        #convert to hex, combine the hex pieces+hexed port
        if client_ip_address.count('.') == 3:
            #dealing with an ipv4 address
            #but, could also be dealing with a DNS name, but how to check for that...
            ip_list=client_ip_address.split('.')
            for i in (range(len(ip_list))):
                #print(str(ip_list[i]))
                ip_list[i]=hex(int(ip_list[i]))
                if len(ip_list[i]) != 4:
                    ip_list[i]=ip_list[i][:2]+'0'+ip_list[i][2:]
                #print(str(ip_list[i]))
            client_address_in_hex_no_port=str(ip_list[0])[2:]+str(ip_list[1])[2:]+str(ip_list[2])[2:]+str(ip_list[3])[2:]
        else:
            #dealing with an ipv6 address here, 
            #or a dns name without exactly 3 dots
            #might want to implement this at some point, maybeh
            address_no_port=client_ip_address

        #convert port to hex
        #print(client_port)
        client_port_in_hex=str(hex(int(client_port)))[2:]
        while len(client_port_in_hex) !=4:
            client_port_in_hex='0'+client_port_in_hex
        #print(ip_port_hex)

        #print(client_ip_address+":"+str(client_port))
        #print(client_address_in_hex_no_port+client_port_in_hex)

        #need to store these in hex
        return [peer_id, is_seed, client_ip_address, client_port, client_address_in_hex_no_port, client_port_in_hex, int(time.time())]

	#compare current time with last_peer_update, if peer exists, and if current time-last_peer_update < minimum_interval then client is silly
    def clientIsSilly(self,client_object):
        #print('pie')
        #if client has a recognized event, then it's okay
        if 'client_event' in client_object:
            if client_object['client_event'].lower() == 'Started'.lower():
                return False
            if client_object['client_event'].lower() == 'Stopped'.lower():
                return False
            if client_object['client_event'].lower() == 'Completed'.lower():
                return False
        global master_info_hash_table
        client_info_hash=hashlib.md5()
        client_info_hash.update(client_object['client_info_hash'].encode('utf-8'))
        client_peer_id=hashlib.md5()
        client_peer_id.update(client_object['client_peer_id'].encode('utf-8'))
        #print('pie2')
        if client_info_hash.hexdigest() in master_info_hash_table:
            if client_peer_id.hexdigest() in master_info_hash_table[client_info_hash.hexdigest()]:
                last_peer_update=master_info_hash_table[client_info_hash.hexdigest()][client_peer_id.hexdigest()][6]
                if int(time.time())-last_peer_update < minimum_interval:
                    #print('silly client found')
                    return True
        return False

    #reset data on all tracked torrents
    def checkDB(self):
        global last_database_cleanup
        global master_info_hash_table

        #remove stale peers here
        #itterate through hashes, for each hash check every peer's last_request time, make sure not empty
        #find all the current keys in the master table
        #for each key (info hashes)
            #find all the client keys (peer ids) in the table
            #for each peer id key
                #set the completed count for that table to 0
                #set the incomplete count to 0 for that table
                #if the client hasn't checked in, remove it
                #if the client is valid, then increment either incomplete or complete
        if len(master_info_hash_table) == 0:
            return
        #print(master_info_hash_table)
        #info_hash_keys=master_info_hash_table.keys()
        info_hash_keys=list(master_info_hash_table)
        #print(info_hash_keys)
        for i in (info_hash_keys):
            #peer_id_keys=master_info_hash_table[i].keys()
            peer_id_keys=list(master_info_hash_table[i])
            #print(peer_id_keys) #all the peers in a torrent's info_hash table+ complete/incomplete
            new_complete=0
            new_incomplete=0
            #remove_list=[]
            for k in (peer_id_keys):
                if k == 'complete' :
                    continue
                if k == 'incomplete':
                    continue
                #print(master_info_hash_table[i][k])  #the data of a peer in a torrent's info_hash table+ complete/incomplete
                if int(time.time())-master_info_hash_table[i][k][6] > consider_peers_dead_after:
                    #remove_list.append(k)
                    print(master_info_hash_table[i][k])
                    del master_info_hash_table[i][k]
                    print('peer removed from info hash table')
            #print(master_info_hash_table[i])  #the data of an info_hash table
            #print(remove_list)
            #for k in (remove_list):
                #print(master_info_hash_table[i][k][0])

            #print('peer removed from info hash table')
            #now that the stale peers have been removed, can modify the remaining seeds/non-seed peers more accurately
            #peer_id_keys=master_info_hash_table[i].keys()
            peer_id_keys=list(master_info_hash_table[i])
            #print(peer_id_keys) #print updated (slim) list of entries in an info_hash table
            for k in (peer_id_keys):
                if k == 'complete' :
                    continue
                if k == 'incomplete':
                    continue
                #print(master_info_hash_table[i][k])
                if master_info_hash_table[i][k][1] == True:
                    new_complete=new_complete+1
                elif master_info_hash_table[i][k][1] == False:
                    new_incomplete=new_incomplete+1
                else:
                    print('error determining client seed status')
            master_info_hash_table[i]['complete']=new_complete
            master_info_hash_table[i]['incomplete']=new_incomplete

        last_database_cleanup=int(time.time())

        #info_hash_keys=master_info_hash_table.keys()
        info_hash_keys=list(master_info_hash_table)
        #print(info_hash_keys)
        for i in (info_hash_keys):
            if len(master_info_hash_table[i]) == 2:
                del master_info_hash_table[i]
        return

    #remove data on a particular torrent (remove each associated peer from it first or not necessary?)
    def deleteTable(self,info_hash):
        global master_info_hash_table
        info_hash=hashlib.md5()
        info_hash.update(client_object['client_info_hash'].encode('utf-8'))
        #check to make sure it exists, then delete it, if it does't exist return an error
        if info_hash.hexdigest() in master_info_hash_table:
            del master_info_hash_table[peer_info_hash.hexdigest()]
        elif info_hash.hexdigest() not in master_info_hash_table:
            print("could not find specified info hash in master table when asked to remove it")
            return 'error'

    #deletes entry (of type list) from the associated table (of type dict)
    def removePeerEntry(self,peer_id,peer_info_hash):
        global master_info_hash_table
        peer_info_hash=hashlib.md5()
        peer_info_hash.update(client_object['client_info_hash'].encode('utf-8'))
        peer_id=hashlib.md5()
        peer_id.update(client_object['client_peer_id'].encode('utf-8'))
        #check to make sure it exists, then delete it, if it does't exist return an error
        if peer_info_hash.hexdigest() in master_info_hash_table:
            if peer_id.hexdigest() in master_info_hash_table[peer_info_hash.hexdigest()]:
                del master_info_hash_table[peer_info_hash.hexdigest()][peer_id.hexdigest()]
            elif peer_id.hexdigest() not in master_info_hash_table[peer_info_hash.hexdigest()]:
                print("could not find specified peer in the torrent's table when asked to remove a peer")
                return 'error'
        elif peer_info_hash.hexdigest() not in master_info_hash_table:
            print("could not find specified info hash in master table when asked to remove a peer")
            return 'error'


class MainHandler(tornado.web.RequestHandler):
    def get(self):
        client_uri = self.request.uri
        client_path = self.request.path
        client_query = self.request.query
        client_remote_ip = self.request.remote_ip
        client_url = self.request.full_url()
        client_uri_dictionary = self.request.arguments
        #client_info_hash = self.get_argument("info_hash")
        #client_peer_id = self.get_argument("peer_id")
        #client_port = self.get_argument("port")
        #client_uploaded = self.get_argument("uploaded")
        global tracker_db

        client_request_dictionary = parseRawRequest(client_query)
        #print("pie")
        #print("client_request_dictionary['client_left']")
        #print(client_request_dictionary['client_left'])
        #print(client_request_dictionary)

        #check for returned error
        #requestObject["error"]=missing_info_hash
        #request should be a human readable string, not an error code according to "offical" 1.0 spec
        if 'error' in client_request_dictionary:
            #self.set_header('Content-Type', 'application/octet-stream')
            self.set_header('Content-Type', 'text/plain')
            bencoded_error=errorHandler(client_request_dictionary['error'])
            self.write(bencoded_error)
            self.flush()
            #self.finish()
            return

        #if not errored out then check to see if peer already exists in db, if so, check to make sure request didn't come too soon
        if tracker_db.clientIsSilly(client_request_dictionary) == True:
            #print('pie3')
            #self.set_header('Content-Type', 'application/octet-stream')
            self.set_header('Content-Type', 'text/plain')
            bencoded_error=errorHandler(request_too_soon)
            self.write(bencoded_error)
            self.flush()
            #self.finish()
            return

        #purge the database if lifespan has expired
        global initialization_time
        global master_info_hash_table
        if int(time.time())-initialization_time > database_lifespan:
            master_info_hash_table=dict({})
            initialization_time=int(time.time())
            print('database erased')

        #update database with new peer if client wasn't silly
        #print('pie4')
        #db.update(client_object,client_remote_ip)
        tracker_db.updateClient(client_request_dictionary,client_remote_ip)

        #if it hasn't happned in a while, cleanup the db of stale data so it doesn't get returned to the peer
        global last_database_cleanup
        if int(time.time())-last_database_cleanup > clean_database_every:
            tracker_db.checkDB()

        #now just need to actually respond back (http over tcp)

        current_client_info_hash=client_request_dictionary['client_info_hash']
        #print(client_request_dictionary)
        clientWantsNormalOrCompactResponse='normal'
        #retrieve relevant peerList from database
        if 'client_compact' in client_request_dictionary:
            #client_request_dictionary['client_compact']=0
            if client_request_dictionary['client_compact'] == '1':
                #print('compact client request detected')
                clientWantsNormalOrCompactResponse='compact'

        #get peerlist from database
        #get_peerList(info_hash,compact status as normal or minimal), returns a peerlist
        peer_List = tracker_db.get_peerList(current_client_info_hash,clientWantsNormalOrCompactResponse)
        #could maybe, retrieve non-seeder list to return to a seeder
        #or could just return the raw peer list for native parsing or fully parse it and return only the finished peer list
        #instead of preparsing it in the function and finishing the parsing in main (architecture not pretty as-is)
        #get_peerList(current_client_info_hash,normal)
        #get_peerList(current_client_info_hash,compact)
        #or like, remove the current client from the list when sending it back to them
        #or like, specify a maximum number of peers to retrieve

        #retrieve torrent statistics
        complete=tracker_db.get_complete(current_client_info_hash)
        incomplete=tracker_db.get_incomplete(current_client_info_hash)

        client_object=client_request_dictionary
        #self.set_header('Content-Type', 'application/octet-stream')
        self.set_header('Content-Type', 'text/plain')
        #def generateClientResponse(client_object,peer_List,complete,incomplete):
        #parse compact,no_peer_id (for dict responses only), numwant for a requestObject
        #interval, min interval (optional), tracker id (optional), complete, incomplete, (peers(dictionary) or peers(binary))
        #optional, if current client_object is a seed, then could strip out other seeds from the response
        #print("pie1")

        #bencode the values
        #print(request_interval)
        #print(minimum_interval)
        #print(complete)
        #print(incomplete)
        bencoded_interval_value=bencode(request_interval,'int')
        bencoded_min_interval_value=bencode(minimum_interval,'int')
        bencoded_complete_value=bencode(complete,'int')
        bencoded_incomplete_value=bencode(incomplete,'int')
        #print(bencoded_complete_value)

        #print(bencoded_complete_string)
        #print(bencoded_complete_value)
        #print(bencoded_incomplete_string)
        #print(bencoded_incomplete_value)
        #print(bencoded_interval_string)
        #print(bencoded_interval_value)
        #print(bencoded_min_interval_string)
        #print(bencoded_min_interval_value)

        #redundant code (from above's clientWantsNormalOrCompactResponse)
        if 'client_compact' in client_object:
            if client_object['client_compact'] == '1':
                client_requested_compact=True
            else:
                client_requested_compact=False
        else:
            client_requested_compact=False

        #count the number available, that's the total_available. then pick whichever is lowest total_available, max_peers_in_response, or numwant 
        if 'client_numwant' in client_object:
            if int(client_object['client_numwant']) < max_peers_in_response:
                client_max_response_count=int(client_object['client_numwant'])
            else:
                client_max_response_count=max_peers_in_response
        else:
            client_max_response_count=max_peers_in_response

        #output the inital bencoded dictionary that will be used for the entire response
        response_global=bencoded_complete_string+bencoded_complete_value+bencoded_incomplete_string+bencoded_incomplete_value+bencoded_interval_string+bencoded_interval_value+bencoded_min_interval_string+bencoded_min_interval_value+bencoded_peers_string
        self.write('d')
        self.write(response_global)

        #now to respond back with the peer list in the format the client requested
        #okay now to figure out how to output the peer list as (dictionary w/peer_id , dictionary w/o peer_id, compact)
        #if raw_encoded_url_string.rfind('-') == -1:
        #binascii.a2b_hex
        #for normal dictionary responses, if the peer list is selected then need to send it out as bytes
        #peer list can contain -ut221-[hexdigits]  or [hexdigits], so detect and encode appropriately
        #for compact responses, the [compacted_peer_list_in_hex] needs to be sent out as bytes, len(works normally)
        #compact responses take the form: 5:peers48:[binary]  and are embedded as a key into the root dictionary of the bencoded response, 
        #not sure if the 48 is the length of the binary "string" in binary or the length of the binary "string" in hex, (assume it's binary first)

        #output for dictionary type:
        #dictionary peer list (multiple strings + bitstreams, difficult to pass back-forth through messages)
        #dictionary w/o peer list 1 string
        #output for compact type:
        #only 1 type but needs: 1string+1bitstream (peers) (can append e at the end)
        if client_requested_compact == False:
            total_available=int(len(peer_List)/3)
            if total_available < client_max_response_count:
                response_count=total_available
            elif total_available >= client_max_response_count:
                response_count=client_max_response_count

            #for normal responses need to know if clients don't want a peer ID included in the response
            if 'client_no_peer_id' in client_object:
                if client_object['client_no_peer_id'] == '1':
                    #if client selected no peer_id, then very easy to respond
                    #build string normally and send it, then return
                    for i in range (len(peer_List)):
                        #if parsing the last item in a pair, assume that it's a port number and bencode it as an int, else assume it's a string (peer_id and ip)
                        if i%3==2:
                            peer_List[i]=bencode(peer_List[i],'int')
                        elif i%3==1:
                            peer_List[i]=bencode(str(peer_List[i]),'string')
                    #now every item other than peer id's have been bencoded
                    #print("peer_List: "+str(peer_List))

                    bencoded_peer_array=[]
                    for i in range (0,len(peer_List),3):
                        bencoded_peer_array.append(bencode(bencoded_ip_string+str(peer_List[i+1])+bencoded_port_string+str(peer_List[i+2]),'dictionary'))

                    bencoded_peer_list=str(bencoded_peer_array[0])
                    for i in range (response_count):
                        if i!=0:
                            bencoded_peer_list=bencoded_peer_list+bencoded_peer_array[i]
                    bencoded_peer_list=bencode(bencoded_peer_list,'list')
                    self.write(bencoded_peer_list)
                    self.write('e')
                    self.flush()
                    #self.finish()
                    return

            #okay so client did not request a compact response and did not say no_peer_id's...let's do this
            #for normal response peer_list is (peer_id,ip, port,peer_id,ip, port,peer_id,ip, port,peer_id,ip, port...n), so multiples of 3
            #need to write prefix
            #need to cycle through peerlist, then
            #determine how many peers are needed (response_count)
            #then loop through every third peer item
                #process i, i+1 and i+2, writing each to output
                #bencode the port/ip and convert
                #write contents
                #(order of dictionary items not important)
            #go to next peer
            #when done, need to write postfix

            self.write('l')
            #this needs a different algorithm to incorporate response_count and to cycle properly
            i=0  #increment by 1 each loop, keep going for this many total loops
            k=0 #increment by 3 each loop, use this to reference the peer_List
            #for normal response peer_list is (peer_id,ip, port,peer_id,ip, port,peer_id,ip, port,peer_id,ip, port...n), so multiples of 3, starting with peer id then -> ip -> port
            while i < response_count:
                self.write('d')
                self.write(bencoded_port_string)
                peer_List[k+2]=bencode(peer_List[k+2],'int')
                self.write(peer_List[k+2])

                self.write(bencoded_ip_string)
                peer_List[k+1]=bencode(str(peer_List[k+1]),'string')
                self.write(peer_List[k+1])

                self.write(bencoded_peer_id_string)
                #spec says that peer_id's must be 20 bytes, assume that's true here (since this should have been checked before being input into db)
                self.write('20:')
                #need to find out of peer id is in ut format, binary format or shadow's format
                if peer_List[k].rfind('-') == -1:
                    #if there is no -, then assume it's pure hex, so just decode and send
                    peer_List[k]=binascii.a2b_hex(peer_List[k])
                    self.write(peer_List[k])
                else:
                    #if there are -'s then need to separate into two parts
                    #write the first part
                    #decode the second part
                    #write the second part (don't save)
                    peer_id_prefix=peer_List[k][:peer_List[k].rfind('-')+1]
                    self.write(peer_id_prefix)
                    peer_id_binary_part=peer_List[k][peer_List[k].rfind('-')+1:]
                    peer_id_binary_part=binascii.a2b_hex(peer_id_binary_part)
                    self.write(peer_id_binary_part)
                self.write('e') #close peer dictionary entry
                i=i+1
                k=k+3
                    
            self.write('e') #close list entry
            #when done, need to write postfix
            self.write('e') #final postfix, close root dictionary
            self.flush()
            #self.finish()
            return

        #so client requested a compact response
        #compact responses take the form: 5:peers48:[binary] and are embedded as a key into the root dictionary of the bencoded response, (so there's a post fix "e" after the peers list)
        #not sure if the 48 is the length of the binary "string" in binary or the length of the binary "string" in hex, (assume it's binary first)
        if client_requested_compact == True:
            #for compact response peer_list is (ip_in_hex, port_in_hex,ip_in_hex, port_in_hex,ip_in_hex, port_in_hex,...n), so multiples of 2
            total_available=int(len(peer_List)/2)
            if total_available < client_max_response_count:
                response_count=total_available
            elif total_available >= client_max_response_count:
                response_count=client_max_response_count

            #combine the ip/port strings with values, every 3 is 1 dictionary
            peer_array=[]
            for i in range (0,len(peer_List),2):
                peer_array.append(peer_List[i]+peer_List[i+1])

            peer_list_in_hex=peer_array[0]
            for i in range (response_count):
                if i!=0:
                    peer_list_in_hex=peer_list_in_hex+peer_array[i]

            peer_list_in_binary=binascii.a2b_hex(peer_list_in_hex)
            peer_list_length=str(len(peer_list_in_binary))

            #   48:[binary]  with a trailing e
            self.write(peer_list_length)
            self.write(':')
            self.write(peer_list_in_binary)
            self.write('e')
            self.flush()
            return

        print("unspecified error")
        self.flush()
        return


class InvalidRequest(tornado.web.RequestHandler):
    def get(self):
        #self.set_header('Content-Type', 'application/octet-stream')
        #self.set_header('Content-Type', 'text/plain')
        #should prolly just send a 404 or access restricted error instead, comment out header type if doing that
        self.send_error(403)
        self.flush()
        #self.finish()

def main():
    parse_command_line()
    global tracker_db
    tracker_db = Database()
    #the only valid request is /announce
    #in order to use /scrape add an entry
    #or to respond to anything /announce* like /announce.php switch which line is commented
    app = tornado.web.Application([
            (r"/announce.*", MainHandler),
            #(r"/announce", MainHandler),
			(r"/.*", InvalidRequest),
            ])
    app.listen(tracker_port)
    tornado.ioloop.IOLoop.current().start()

if __name__ == "__main__":
    main()
